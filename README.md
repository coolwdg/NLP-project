# NLP-project
# 大作业项目说明

## 项目概述
本项目围绕大模型的应用与评估展开，包含了直接调用大模型进行多轮对话、知识库相关操作、问题评估以及结果分析等功能。主要实现了对关键词或问题准确率的评估，同时加入了大模型评估环节，并对反例进行测试。

## 文件说明

### 代码文件
1. **api.py**
    - 功能：直接调用大模型，提供完整的多轮对话代码演示，可直接运行。
    - 使用方法：直接运行该脚本即可开始多轮对话。

2. **evaluate.py**
    - 功能：用于评估关键词或者问题的准确率，不加入大模型评估结果，但保留了EM（Exact Match）、F1指标。
    - 使用方法：在脚本中设置相关参数，运行脚本即可进行评估。

3. **model_evaluate.py**
    - 功能：相较于`evaluate.py`，加入了大模型评估。
    - 使用方法：设置好相关参数后运行脚本，进行更全面的评估。

4. **fanliceshi.py**
    - 功能：用于反例测试。
    - 使用方法：根据需求设置反例数据，运行脚本进行测试。

5. **read.py**
    - 功能：一个小脚本，用于读取文档并切分，同时随机选取一些TEXT，按照需要格式输出（如`keyword.txt`）。
    - 使用方法：修改脚本中的输入文件路径和输出文件路径，运行脚本即可完成数据处理。

6. **readfanli.py**
    - 功能：与`read.py`类似，用于读取反例相关数据并处理。
    - 使用方法：修改输入和输出文件路径，运行脚本进行数据处理。

7. **sdk.py**
    - 功能：是Python创建知识库的代码实现。
    - 使用方法：运行脚本，根据提示完成知识库的创建操作。

8. **test.py**
    - 功能：用于测试文档检索。
    - 使用方法：设置好相关参数，运行脚本进行文档检索测试。

### 数据文件
1. **requirements.txt**
    - 功能：记录项目所需的Python依赖库及其版本。
    - 使用方法：在虚拟环境中使用`pip install -r requirements.txt`安装所需依赖。

2. **evaluation_res.txt**
    - 功能：保存了评估结果，包含问题、预测答案、标准答案、ROUGE-L指标以及大模型评估结果等信息。
    - 使用方法：查看文件内容，分析评估结果。

3. **fanli.txt**
    - 功能：包括了设计的反例和源TEXT。
    - 使用方法：作为反例测试的输入数据。

4. **fanli_res.txt**
    - 功能：包括了反例测试最后的结果。
    - 使用方法：查看文件内容，了解反例测试情况。

5. **keyword.txt**
    - 功能：随机选取的关键词。
    - 使用方法：可作为评估关键词准确率的输入数据。

6. **question.txt**
    - 功能：随机选取的问题。
    - 使用方法：可作为评估问题准确率的输入数据。

7. **output.jsonl**
    - 功能：按照标准数据集格式生成的样例，可用作微调。
    - 使用方法：在进行模型微调时，将其作为训练数据。

8. **test_answer.txt**
    - 功能：根据答案设计的模板。
    - 使用方法：作为评估时的标准答案参考。


## 环境配置
1. 创建虚拟环境（可选）：
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate  # Windows
```

2. 安装依赖库：
```bash
pip install -r requirements.txt
```

## 运行步骤
1. 根据需求修改各脚本中的相关参数，如文件路径、模型名称等。
2. 运行相应的脚本，如进行评估可运行`evaluate.py`或`model_evaluate.py`，进行反例测试可运行`fanliceshi.py`等。
3. 查看输出结果，分析评估情况。

## 注意事项
- 部分脚本需要设置相关的API密钥、账号ID等信息，请根据实际情况进行配置。
- 在运行脚本前，请确保输入数据文件存在且格式正确。
